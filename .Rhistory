data_for_year <- subset_data_year
# Calculate the mean and standard deviation of SMB
mean_smb <- mean(data_for_year$smb, na.rm = TRUE)
sd_smb <- sd(data_for_year$smb, na.rm = TRUE)
# Add the results to the results data frame
results <- rbind(results, data.frame(Year=year, Mean_SMB=mean_smb, SD_SMB=sd_smb))
}
# Print the results data frame
print(results)
# Load the required libraries
library(dplyr)
# Read the data
factor_returns <- read.csv("factor_returns.csv")
# Add a year column
factor_returns$year <- substr(factor_returns$date, 1, 4)
# Initialize an empty data frame to store the results
results <- data.frame(Year=integer(), Mean_SMB=numeric(), SD_SMB=numeric())
# Loop over the years
for (year in 2000:2005) {
# Subset the data for the current year
subset_data_year <- subset(factor_returns, factor_returns[["year"]] == year)
# Extract the SMB column
smb_data_year <- subset_data_year$smb
# Calculate the mean and standard deviation of SMB
mean_smb <- mean(smb_data_year, na.rm = TRUE)
sd_smb <- sd(smb_data_year, na.rm = TRUE)
# Add the results to the results data frame
results <- rbind(results, data.frame(Year=year, Mean_SMB=mean_smb, SD_SMB=sd_smb))
}
# Print the results data frame
print(results)
# Load the required libraries
library(dplyr)
# Read the data
factor_returns <- read.csv("factor_returns.csv")
# Add a year column
factor_returns$year <- substr(factor_returns$date, 1, 4)
# Initialize an empty data frame to store the results
results <- data.frame(Year=integer(), Mean_SMB=numeric(), SD_SMB=numeric())
# Loop over the years
for (year in 2000:2005) {
# Subset the data for the current year
subset_data_year <- subset(factor_returns, factor_returns[["year"]] == year)
# Extract the SMB column
smb_data_year <- subset_data_year$smb
# Calculate the mean and standard deviation of SMB
mean_smb <- mean(smb_data_year, na.rm = TRUE)
sd_smb <- sd(smb_data_year, na.rm = TRUE)
# Add the results to the results data frame
results <- rbind(results, data.frame(Year=year, Mean_SMB=mean_smb, SD_SMB=sd_smb))
}
# Print the results data frame
print(results)
# Task 1: First steps
setwd("~/Documents/Financial Econometrics")
# Task 1: First steps
setwd("/Users/sinfjell/Library/CloudStorage/OneDrive-NorgesHandelshøyskole/FIE401/Github")
library(plm)
X <- rnorm(100)
Y <- rnorm(100)
ls()
plot(X, Y)
rm(X, Y)
# Task 2: Data objects and structures
numbers <- 1:100
df <- data.frame(digits = numbers, year = 1843, text = "Some characters")
# Task 3: Import, export, and save data
factor_returns <- read.csv("factor_returns.csv")
save(factor_returns, file = "factor_returns.RData")
write.table(factor_returns, file = "factor_returns.txt", sep = "\t")
list.files()
# Task 4: Analysis of profitability
mkt <- factor_returns$mkt.rf + factor_returns$rf
t_stat_mkt <- mean(mkt) / sd(mkt) * sqrt(length(mkt))
print(t_stat_mkt)
t_stat_mkt.rf <- mean(factor_returns$mkt.rf) / sd(factor_returns$mkt.rf) * sqrt(length(factor_returns$mkt.rf))
print(t_stat_mkt.rf)
t_stat_SMB <- mean(factor_returns$SMB) / sd(factor_returns$SMB) * sqrt(length(factor_returns$SMB))
print(t_stat_SMB)
t_stat_HML <- mean(factor_returns$HML) / sd(factor_returns$HML) * sqrt(length(factor_returns$HML))
print(t_stat_HML)
# Task 5: Manipulation
recent_SMB <- factor_returns$SMB[factor_returns$Date > "2000-01-01"]
t_stat_recent_SMB <- mean(recent_SMB) / sd(recent_SMB) * sqrt(length(recent_SMB))
print(t_stat_recent_SMB)
summary(recent_SMB)
hist(recent_SMB)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
factor_returns <- read.csv("factor_returns.csv")
# Get the year
year <- factor_returns$Date %>%
substr(1, 4)
# Calculate mean and standard deviation of SMB for each year
mean_SMB <- sapply(year, function(y) {
mean(factor_returns$SMB[factor_returns$Date > y])
})
sd_SMB <- sapply(year, function(y) {
sd(factor_returns$SMB[factor_returns$Date > y])
})
# Print the results
data.frame(year, mean_SMB, sd_SMB)
library(tidyverse)
factor_returns <- read.csv("factor_returns.csv")
# Get the year
year <- factor_returns$Date %>%
substr(1, 4)
# Calculate mean and standard deviation of SMB for each year
mean_SMB <- sapply(year, function(y) {
mean(factor_returns$SMB[factor_returns$Date > y])
})
sd_SMB <- sapply(year, function(y) {
sd(factor_returns$SMB[factor_returns$Date > y])
})
# Print the results
data.frame(year, mean_SMB, sd_SMB)
library(tidyverse)
factor_returns <- read.csv("factor_returns.csv")
# Get the year
year <- factor_returns$Date %>%
substr(1, 4)
# Calculate mean and standard deviation of SMB for each year
mean_SMB <- sapply(year, function(y) {
ifelse(y < 2000, NA, mean(factor_returns$SMB[factor_returns$Date > y]))
})
sd_SMB <- sapply(year, function(y) {
ifelse(y < 2000, NA, sd(factor_returns$SMB[factor_returns$Date > y]))
})
# Print the results
data.frame(year, mean_SMB, sd_SMB)
# Display the results data frame
print(results)
# Save the subset data to a variable
data_for_year <- subset_data_year
print(paste("Processing year:", year))
# Save the subset data to a variable
data_for_year <- subset_data_year
# Assignment related to week 2
# https://nhh.instructure.com/courses/2222/files/352423?wrap=1
# Task 1 ------------------------------------------------------------------
# Open RStudio manually
# Set the working directory
setwd("/Users/sinfjell/Library/CloudStorage/OneDrive-NorgesHandelshøyskole/FIE401/Github")
# Install and load the "plm" package
# installed it in the console with install.packages
library(plm)
# Declare two variables X and Y
X <- rnorm(100)
Y <- rnorm(100)
# Check if variables are in working memory
ls()
# Make a scatterplot
plot(x = X, y = Y)
# Delete variables
rm(X, Y)
# Check if variables are still in memory
ls()
# Task 2 ------------------------------------------------------------------
# Create a vector
my_vector <- 1:100
# Create a dataframe
my_dataframe <- data.frame(digits = my_vector, year = rep(1843, 100), text = "some_text_here")
# Task 3 ------------------------------------------------------------------
# Read the CSV file
factor_returns <- read.csv("factor_returns.csv")
# Save the data
save(factor_returns, file = "factor_returns.RData")
# Write the data as a .txt file
write.table(factor_returns, "factor_returns.txt", sep = "\t")
# Check if files are in the working directory
list.files()
# Task 4 ------------------------------------------------------------------
# Calculate the t-statistic for market returns
t_stat <- (mean(factor_returns$mkt) / sd(factor_returns$mkt)) *
sqrt(length(factor_returns$mkt))
# Print the t-statistic
print(t_stat)
# Interpretation:
# The t_stat is higher than 1.96, which means we can reject the null hypothesis
# that the mean market return is zero at the 5% significance level.
# This suggests that the market returns are significantly positive.
# Therefore, investing in the market portfolio could be a good idea.
# Task 5 ------------------------------------------------------------------
# Task 5: Manipulation
# Load the data
factor_returns <- read.csv("factor_returns.csv")
# Convert the date to numeric for easier filtering
factor_returns$date <- as.numeric(factor_returns$date)
# Extract SMB, mkt, and HML for all days starting from 2000
subset_data <- subset(factor_returns, date >= 20000101)
# Compute t-statistics for SMB
t_stat_smb <- (mean(subset_data$smb) / sd(subset_data$smb)) * sqrt(length(subset_data$smb))
print(paste("t-statistic for SMB: ", t_stat_smb))
# Interpretation: If t_stat_smb is greater than 1.96 or less than -1.96, SMB has significantly positive/negative returns
if (abs(t_stat_smb) > 1.96) {
print("SMB has significantly different returns from zero.")
} else {
print("SMB does not have significantly different returns from zero.")
}
# Compute t-statistics for mkt
t_stat_mkt <- (mean(subset_data$mkt.rf) / sd(subset_data$mkt.rf)) * sqrt(length(subset_data$mkt.rf))
print(paste("t-statistic for mkt: ", t_stat_mkt))
# Interpretation: If t_stat_mkt is greater than 1.96 or less than -1.96, mkt has significantly positive/negative returns
if (abs(t_stat_mkt) > 1.96) {
print("Market has significantly different returns from zero.")
} else {
print("Market does not have significantly different returns from zero.")
}
# Compute t-statistics for HML
t_stat_hml <- (mean(subset_data$hml) / sd(subset_data$hml)) * sqrt(length(subset_data$hml))
print(paste("t-statistic for HML: ", t_stat_hml))
# Interpretation: If t_stat_hml is greater than 1.96 or less than -1.96, HML has significantly positive/negative returns
if (abs(t_stat_hml) > 1.96) {
print("HML has significantly different returns from zero.")
} else {
print("HML does not have significantly different returns from zero.")
}
# Summary statistics
summary(subset_data[, c("smb", "mkt.rf", "hml")])
# Histograms
hist(subset_data$smb, main="Histogram of SMB", xlab="SMB")
hist(subset_data$mkt.rf, main="Histogram of Market Returns", xlab="Market Returns")
hist(subset_data$hml, main="Histogram of HML", xlab="HML")
# Task 6 ------------------------------------------------------------------
# Extract the year from the date, add it to factor_returns
factor_returns$year <- substr(factor_returns$date, 1, 4)
# Initialize an empty data frame to store the results
results <- data.frame(Year=integer(), Mean_SMB=numeric(), SD_SMB=numeric())
for (year in 2000:2005) {
subset_data_year <- subset(factor_returns, factor_returns[["year"]] == as.character(year))
# Save the subset data to a variable
data_for_year <- subset_data_year
print(paste("Processing year:", year))
print(paste("Number of rows:", nrow(data_for_year)))
mean_smb <- mean(data_for_year$smb, na.rm = TRUE)
sd_smb <- sd(data_for_year$smb, na.rm = TRUE)
print(paste("Computed mean_smb for year ", year, ": ", mean_smb))
print(paste("Computed sd_smb for year ", year, ": ", sd_smb))
# Add the results to the results data frame
results <- rbind(results, data.frame(Year=year, Mean_SMB=mean_smb, SD_SMB=sd_smb))
}
# Display the results data frame
print(results)
# Save the subset data to a variable
data_for_year <- subset_data_year
View(data_for_year)
subset_data_year <- subset(factor_returns, factor_returns[["year"]] == as.character(year))
subset_data_year <- subset(factor_returns, factor_returns[["year"]] == as.character(2000))
View(subset_data_year)
View(subset_data_year)
install.packages("lfe")
install.packages("lfe")
# Set WD
setwd("/Users/sinfjell/Library/CloudStorage/OneDrive-NorgesHandelshøyskole/FIE401/Assignment-2/github")
# Load necessary libraries
require(DescTools)
require(plm)
require(dplyr)
require(lmtest)
library(sandwich)
require(stargazer)
require(tidyverse)
# Load the data
data <- read.csv("SVI.csv")
data_original <- read.csv("SVI.csv")
# Remove missing observations and format date
data <- na.omit(data)
data$date <- as.Date(data$date, format="%d%b%Y")
# Declare the dataset to be a panel data
data <- pdata.frame(data, index = c("ticker","date"))
# How many rows were removed?
original_rows <- nrow(data_original)
cleaned_rows <- nrow(data)
rows_removed <- original_rows - cleaned_rows
print(paste("Original dataset is", original_rows, "rows long, while this dataset is",
cleaned_rows, "rows long. Meaning", rows_removed, "rows were removed."))
# Task 1 ------------------------------------------------------------------
# Prepare your data
data$Abs_RET <- abs(data$RET)  # Compute absolute value of returns
data$ln_SVI <- log(1 + data$SVI)  # Compute ln(1 + SVI)
# Model with homoscedastic standard errors
homoscedastic_model <- lm(ln_SVI ~ Abs_RET, data = data)
# Obtain heteroskedasticity-robust standard errors
robust_se <- coeftest(homoscedastic_model, vcov = vcovHC(homoscedastic_model, type = "HC3"))[, 2]
# Obtain stock-clustered standard errors
clustered_se <- coeftest(homoscedastic_model, vcov = vcovCL(homoscedastic_model, cluster = ~ ticker, data = data))[, 2]
# Generate regression table
stargazer(homoscedastic_model, homoscedastic_model, homoscedastic_model,
se = list(NULL, robust_se, clustered_se),
title = "Regression Table",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
column.labels = c("Homoskedastic", "Heteroskedasticity-Corrected", "Stock-Clustered"),
type = "text", report = "vc*t",
covariate.labels = c("Stock returns (ABS)"),
dep.var.labels = "Log of Google Searchs")
# Plot
# Preparing predictions from the model
# Convert panel data variables to standard vector format for plotting
RET_vector <- as.vector(data$RET)
ln_SVI_vector <- as.vector(data$ln_SVI)
# Preparing predictions from the model
predicted_vector <- as.vector(predict(homoscedastic_model, data))
# Plotting the graph
plot(RET_vector, ln_SVI_vector,
xlab = "Stock returns",
ylab = "Log-adjusted Google Searches",
main = "Google Searches based on the ticker returns",
pch = 20)
points(RET_vector, predicted_vector, col = "blue", pch = 20)  # Adding predicted points
# Task 2 ------------------------------------------------------------------
# Prepare data for regression analysis
manipulated_data <- data %>%
group_by(ticker) %>%
arrange(date) %>%
mutate(ln_SVI_lag = lag(log(1 + SVI), order_by = date))  # Compute ln(1 + SVI)_lag correctly using order_by
# Convert the result back to a panel data object
data <- pdata.frame(manipulated_data, index = c("ticker", "date"))
# Handle missing values in ln_SVI_lag
data <- data %>% filter(!is.na(ln_SVI_lag))
data$Abs_vwretd <- abs(data$vwretd)  # Compute absolute value of market return
# Estimate Model 1
model_1 <- lm(ln_SVI ~ Abs_RET + Abs_vwretd, data = data)
# Cluster standard errors at stock level for Model 1
clustered_se_model_1 <- coeftest(model_1, vcov = vcovCL(model_1, cluster = ~ ticker, data = data))[, 2]
# Estimate Model 2
model_2 <- lm(ln_SVI ~ Abs_RET + ln_SVI_lag, data = data)
# Cluster standard errors at stock level for Model 2
clustered_se_model_2 <- coeftest(model_2, vcov = vcovCL(model_2, cluster = ~ ticker, data = data))[, 2]
# Load the lfe package
library(lfe)
# Estimate Model 3 using felm() with both stock and day fixed effects
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Summary of Model 3
summary(model_3_fe)
# Create a regression table
stargazer(model_1, model_2, model_3,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
column.labels = c("Model 1", "Model 2", "Model 3"),
type = "text", report = "vc*t",
covariate.labels = c("Stock returns (ABS)", "Index return (ABS)",
"Log of Google Searches yesterday"),
dep.var.labels = "Log of Google Searches")
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3, vcov = vcovCL(model_3, cluster = ~ ticker, data = data))[, 2]
# Load the lfe package
library(lfe)
# Estimate Model 3 using felm() with both stock and day fixed effects
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Summary of Model 3
summary(model_3_fe)
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "sss"))[, 2]
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t")
# Task 3 ------------------------------------------------------------------
# Model 1: Stock Fixed Effects
model_1_fe <- plm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag, data = data, model = "within", effect = "individual")
# Cluster standard errors at stock level for Model 1
clustered_se_model_1 <- coeftest(model_1_fe, vcov = vcovHC(model_1_fe, cluster = "group", type = "sss"))[, 2]
# Model 2: Day Fixed Effects
model_2_fe <- plm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag, data = data, model = "within", effect = "time")
# Cluster standard errors at stock level for Model 2
clustered_se_model_2 <- coeftest(model_2_fe, vcov = vcovHC(model_2_fe, cluster = "group", type = "sss"))[, 2]
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t")
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "sss"))[, 2]
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t")
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "sss"))[, 2]
# Estimate Model 3 using felm() with both stock and day fixed effects
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "H2C"))[, 2]
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "HC3"))[, 2]
# Estimate Model 3 using felm() with both stock and day fixed effects
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Summary of Model 3
summary(model_3_fe)
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "HC3"))[, 2]
# Estimate Model 3 using felm() with both stock and day fixed effects
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Summary of Model 3
summary(model_3_fe)
# Cluster standard errors at stock level for Model 3
clustered_se_model_3 <- coeftest(model_3_fe, vcov = vcovHC(model_3_fe, cluster = "group", type = "HC3"))[, 2]
# Estimate your model using felm
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Obtain clustered standard errors
clustered_se_model_3 <- summary(model_3_fe, robust = TRUE)$coefficients[,2]
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t")
# Task 3 ------------------------------------------------------------------
# Model 1: Stock Fixed Effects
model_1_fe <- plm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag, data = data, model = "within", effect = "individual")
# Cluster standard errors at stock level for Model 1
clustered_se_model_1 <- coeftest(model_1_fe, vcov = vcovHC(model_1_fe, cluster = "group", type = "sss"))[, 2]
# Model 2: Day Fixed Effects
model_2_fe <- plm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag, data = data, model = "within", effect = "time")
# Cluster standard errors at stock level for Model 2
clustered_se_model_2 <- coeftest(model_2_fe, vcov = vcovHC(model_2_fe, cluster = "group", type = "sss"))[, 2]
# Model 3: Both Stock and Day Fixed Effects
# Example using lm() for two-way fixed effects
#model_3_fe <- plm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag, data = data, model = "within", effect = "twoway")
# Load the lfe package
library(lfe)
# Estimate your model using felm
model_3_fe <- felm(ln_SVI ~ Abs_RET + Abs_vwretd + ln_SVI_lag | factor(ticker) + factor(date), data = data)
# Obtain clustered standard errors
clustered_se_model_3 <- summary(model_3_fe, robust = TRUE)$coefficients[,2]
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = FALSE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t")
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = TRUE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t",
covariate.labels = c("Stock returns (ABS)", "Index return (ABS)",
"Lagged Log of Google Searches"))
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = TRUE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t",
covariate.labels = c("Stock returns (ABS)", "Index return (ABS)",
"Lagged Log of Google Searches"))
# Create a regression table
stargazer(model_1_fe, model_2_fe, model_3_fe,
se = list(clustered_se_model_1, clustered_se_model_2, clustered_se_model_3),
title = "Regression Table with Controls and Fixed Effects",
header = TRUE,
model.names = FALSE,
omit.stat = "all",
# add.lines = list(c('Stock FE', 'Yes', 'No', 'Yes'),
#               c('Day FE', 'No', 'Yes', 'Yes')),
#column.labels = c("Model 1 (Stock FE)", "Model 2 (Day FE)", "Model 3 (Stock & Day FE)"),
type = "text", report = "vc*t",
covariate.labels = c("Stock returns (ABS)", "Index return (ABS)",
"Lagged Log of Google Searches"),
dep.var.labels = "Log of Google Searches")
getwd()
